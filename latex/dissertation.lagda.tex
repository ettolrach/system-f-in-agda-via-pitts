% UG project example file, February 2024
%
%   Added the "online" option for equal margins, February 2024 [Hiroshi Shimodaira, Iain Murray]
%   A minor change in citation, September 2023 [Hiroshi Shimodaira]
%
% Do not change the first two lines of code, except you may delete "logo," if causing problems.
% Understand any problems and seek approval before assuming it's ok to remove ugcheck.
\documentclass[logo,bsc,singlespacing,parskip,online]{infthesis}
\usepackage{ugcheck}


% Include any packages you need below, but don't include any that change the page
% layout or style of the dissertation. By including the ugcheck package above,
% you should catch most accidental changes of page layout though.

\usepackage{microtype} % recommended, but you can remove if it causes problems
\usepackage[round]{natbib} % recommended for citations

% === Custom packages === %

% Syntax highlighting
\usepackage{minted}
% BNF
\usepackage{simplebnf}
% Inference rules
\usepackage{mathpartir}
% Agda
\usepackage{agda}
\AgdaNoSpaceAroundCode{}
% Hide in output
\usepackage{comment}
% Colour
\usepackage{xcolor}

% Unicode

\usepackage{fontspec}
\usepackage{newunicodechar}
\newfontface{\notosansmono}{NotoSansMono-Regular.ttf}[Path = fonts/]
\newfontface{\ibmplexmath}{IBMPlexMath-Regular.otf}[Path = fonts/]
\newfontface{\hack}{HackNerdFontMono-Regular.ttf}[Path = fonts/]
\newunicodechar{ℕ}{{\notosansmono{ℕ}}}
\newunicodechar{∀}{{\notosansmono{∀}}}
\newunicodechar{≡}{{\notosansmono{≡}}}
\newunicodechar{≥}{{\notosansmono{≥}}}
\newunicodechar{≤}{{\notosansmono{≤}}}
\newunicodechar{≰}{{\notosansmono{≰}}}
\newunicodechar{⊔}{{\notosansmono{⊔}}}
\newunicodechar{≟}{{\notosansmono{≟}}}
\newunicodechar{⇒}{{\hack{⇒}}}
\newunicodechar{≢}{{\notosansmono{≢}}}
\newunicodechar{≮}{{\notosansmono{≮}}}
\newunicodechar{⟪}{{\notosansmono{⟪}}}
\newunicodechar{⟫}{{\notosansmono{⟫}}}
\newunicodechar{⊤}{{\notosansmono{⊤}}}
\newunicodechar{⊥}{{\notosansmono{⊥}}}
\newunicodechar{∣}{{\notosansmono{∣}}}
\newunicodechar{⟨}{{\notosansmono{⟨}}}
\newunicodechar{⟩}{{\notosansmono{⟩}}}
\newunicodechar{∎}{{\notosansmono{∎}}}
\newunicodechar{⌊}{{\notosansmono{⌊}}}
\newunicodechar{⌋}{{\notosansmono{⌋}}}
\newunicodechar{₁}{{\notosansmono{₁}}}
\newunicodechar{₂}{{\notosansmono{₂}}}
\newunicodechar{∃}{{\notosansmono{∃}}}
\newunicodechar{∷}{{\notosansmono{∷}}}
\newunicodechar{∈}{{\notosansmono{∈}}}
\newunicodechar{∉}{{\notosansmono{∉}}}
\newunicodechar{λ}{{\notosansmono{λ}}}
\newunicodechar{И}{{\notosansmono{И}}}
\newunicodechar{∘}{{\notosansmono{∘}}}
\newunicodechar{≠}{{\notosansmono{≠}}}
\newunicodechar{‵}{{\notosansmono{‵}}}
\newunicodechar{ƛ}{{\notosansmono{ƛ}}}
\newunicodechar{≻}{{\ibmplexmath{≻}}}
\newunicodechar{⦃}{{\ibmplexmath{⦃}}}
\newunicodechar{⦄}{{\ibmplexmath{⦄}}}
\newunicodechar{′}{{\notosansmono{′}}}
\newunicodechar{∋}{{\notosansmono{∋}}}
\newunicodechar{⦂}{{\ibmplexmath{⦂}}}
\newunicodechar{∅}{{\hack{∅}}}
\newunicodechar{⊢}{{\hack{⊢}}}
\newunicodechar{ξ}{{\notosansmono{ξ}}}
\newunicodechar{β}{{\notosansmono{β}}}
\newunicodechar{↠}{{\hack{↠}}}
\newunicodechar{ρ}{{\notosansmono{ρ}}}

% Maths:

\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xurl}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\Real}{Re}
\DeclareMathOperator{\Imag}{Im}
\DeclareMathOperator{\complex}{\mathbb{C}}
\DeclareMathOperator{\reals}{\mathbb{R}}
\DeclareMathOperator{\nat}{\mathbb{N}}
\DeclareMathOperator{\integer}{\mathbb{Z}}
\DeclareMathOperator{\rational}{\mathbb{Q}}
\DeclareMathOperator{\Log}{Log}
\DeclareMathOperator{\Arg}{Arg}
\DeclareMathOperator{\cof}{\text{И}}

% Use minted for Agda

\let\oldcode\code
\NewCommandCopy{\mintedcopy}{\minted}
\NewCommandCopy{\endmintedcopy}{\endminted}
% Adapted from https://tex.stackexchange.com/a/488451/202867
\renewenvironment{code}{\mintedcopy[breaklines,breaksymbolleft=\;]{agda}}{\endmintedcopy}
% \let\oldcode\code
% % Adapted from https://tex.stackexchange.com/a/488451/202867
% \def\code{\minted{agda}}

\begin{document}
\begin{preliminary}

\title{System F in Agda via Pitts}

\author{Charlotte Ausel}

% CHOOSE YOUR DEGREE a):
% please leave just one of the following un-commented
% \course{Artificial Intelligence}
%\course{Artificial Intelligence and Computer Science}
%\course{Artificial Intelligence and Mathematics}
%\course{Artificial Intelligence and Software Engineering}
%\course{Cognitive Science}
%\course{Computer Science}
%\course{Computer Science and Management Science}
\course{Computer Science and Mathematics}
%\course{Computer Science and Physics}
%\course{Software Engineering}
%\course{Master of Informatics} % MInf students

% CHOOSE YOUR DEGREE b):
% please leave just one of the following un-commented
%\project{MInf Project (Part 1) Report}  % 4th year MInf students
%\project{MInf Project (Part 2) Report}  % 5th year MInf students
\project{4th Year Project Report}        % all other UG4 students


\date{\today}

\abstract{
This skeleton demonstrates how to use the \texttt{infthesis} style for
undergraduate dissertations in the School of Informatics. It also emphasises the
page limit, and that you must not deviate from the required style.
The file \texttt{skeleton.tex} generates this document and should be used as a
starting point for your thesis. Replace this abstract text with a concise
summary of your report.
}

\maketitle

\newenvironment{ethics}
   {\begin{frontenv}{Research Ethics Approval}{\LARGE}}
   {\end{frontenv}\newpage}

\begin{ethics}
This project was planned in accordance with the Informatics Research
Ethics policy. It did not involve any aspects that required approval
from the Informatics Research Ethics committee.

\standarddeclaration
\end{ethics}


\begin{acknowledgements}
Any acknowledgements go here.
\end{acknowledgements}


\tableofcontents
\end{preliminary}


\chapter{Introduction}

TODO.

This document is a literate Agda file and uses {\color{violet}colour}. Please see appendix
\ref{appendix:compilation_instructions} for details.

\begin{code}
module dissertation where
\end{code}

\chapter{Background}

\section{Agda}
Agda is a dependently-typed functional programming language based on Martin-Löf type theory, which
makes it suitable as a proof-assistant using intuitionistic logic \citep{norell_towards_2007}.
% Its
% syntax is very similar to Haskell, and in fact, the two are closely related; the Agda compiler is a
% transpiler to Haskell, and the Haskell standard library can be used in Agda
% \citep{kusee_compiling_2017}. Yet, Agda has stricter limitations on recursive functions and some
% other such language features which, if included, would make it harder to reason about proofs
% \citep{berghofer_brief_2009}.

In Agda, a lot of definitions are done inductively, or in computing terms, using recursion. For
example, following the Peano axioms for the natural numbers $\nat$ \citep{boolos_freges_1995}, we
may define them like so.

\begin{code}
module Example where
  data ℕ : Set where
    zero : ℕ
    suc  : ℕ → ℕ
\end{code}


\paragraph*{Propositions as types.} A connection which was first noted by William A. Howard in 1969
\citep{howard_formulae-as-types_1980}, there is a direct correspondence between proofs and programs.
\citet{wadler_propositions_2015} calls this correspondence \textit{propositions as types}, and it's
called the Curry-Howard correspondence elsewhere. Thanks to this correspondence, a correct Agda
function with the appropriate type signature matching the claim (proposition) suffices for a proof.
This is the idea behind proof assistants (aka. theorem provers) in general. So a proof that addition
is associative would use recursion, which corresponds to induction, as shown below.

\begin{code}
  -- We can import from the standard library, here we're using
  -- the reflexive and congruence properties of equality.
  open import Relation.Binary.PropositionalEquality
    using (_≡_; refl; cong)

  _+_ : ℕ → ℕ → ℕ
  zero  + m = m
  suc n + m = suc (n + m)

  +-assoc : ∀ (m n p : ℕ) → (m + n) + p ≡ m + (n + p)
  +-assoc zero    n p = refl
  +-assoc (suc m) n p = cong suc (+-assoc m n p)
\end{code}

We will need to import a lot of functions from the Agda standard library
\citep{the_agda_community_agda_2024}. These imports are omitted here, but are available in the full
source file (see appendix \ref{appendix:compilation_instructions}).
\begin{comment}
\begin{code}
-- Data types (naturals, strings, characters)
open import Data.Nat using (ℕ; zero; suc; _<_; _≥_; _≤_; _≤?_; _<?_; z≤n; s≤s; _⊔_)
  renaming (_≟_ to _≟ℕ_)
open import Data.Nat.Properties using (≤-refl; ≤-trans; ≤-<-trans; <-≤-trans; ≤-antisym; ≤-total;
  +-mono-≤; n≤1+n; m≤n⇒m≤1+n; suc-injective; <⇒≢; ≰⇒>; ≮⇒≥)
open import Data.String using (String; fromList) renaming (_≟_ to _≟str_; _++_ to _++str_;
  length to str-length; toList to ⟪_⟫)
open import Data.Char using (Char)
open import Data.Char.Properties using () renaming (_≟_ to _≟char_)

-- Function manipulation.
open import Function using (_∘_; flip; it; id; case_returning_of_)

-- Relations and predicates/decidability.
import Relation.Binary.PropositionalEquality as Eq
open Eq using (_≡_; _≢_; refl; sym; trans; cong; cong-app; cong₂)
open Eq.≡-Reasoning using (begin_; step-≡-∣; step-≡-⟩; _∎)
open import Relation.Binary.Definitions using (DecidableEquality)
open import Relation.Nullary.Decidable using (Dec; yes; no; True; False; toWitnessFalse;
  toWitness; fromWitness; ¬?; ⌊_⌋; From-yes)
open import Relation.Unary using (Decidable)
open import Relation.Binary using () renaming (Decidable to BinaryDecidable)
open import Relation.Nullary.Negation using (¬_; contradiction)
open import Data.Empty using (⊥-elim)

-- Products and exists quantifier.
open import Data.Product using (_×_; proj₁; proj₂; ∃-syntax) renaming (_,_ to ⟨_,_⟩)

-- Lists.
open import Data.List using (List; []; _∷_; _++_; length; filter; map; foldr; head; replicate)
open import Data.List.Properties using (≡-dec)
import Data.List.Membership.DecPropositional as DecPropMembership
open import Data.List.Relation.Unary.All using (All; all?; lookup)
  renaming (fromList to All-fromList; toList to All-toList)
open import Data.List.Relation.Unary.Any using (Any; here; there)
open import Data.List.Extrema Data.Nat.Properties.≤-totalOrder using (max; xs≤max)

-- Import list membership using List Char comparisons.
_≟lchar_ : ∀ (xs ys : List Char) → Dec (xs ≡ ys)
xs ≟lchar ys = ≡-dec (_≟char_) xs ys

open DecPropMembership _≟lchar_ using (_∈_; _∉_; _∈?_)
\end{code}

Include some infixes.

\begin{code}
infix 4 _—→_
\end{code}
\end{comment}

\section{Cofinite Quantification}

\input{cofinite.lagda}

\section{The Lambda Calculus and System F}

\paragraph*{The $\lambda$-calculus.}
The $\lambda$-calculus (pronounced \textit{lambda calculus}), is a theoretical model of computation
developed by Alonzo Church in the 1930s \citep{church_set_1932} and is the basis for System F. It
looks and works similarly to familiar functional programming languages, yet its definition is as
minimal as possible while still being Turing-complete. Although Turing machines would be invented
after the $\lambda$-calculus \citep{turing_computable_1937}, `turing-complete' has become a
shorthand for `universal method of computation'. Such a universal method was not Church's initial
goal, but is why we're still interested in the $\lambda$-calculus. A brief summary is provided here,
a more complete study can be found in \cite{pierce_types_2002}.

We have the following BNF grammar for any $\lambda$-calculus term $t$.
\begin{center}
\begin{bnf}
  $t$ ::=
  | $x$ : variables
  | $\lambda \, x. t$ : ($\lambda$)-abstractions
  | $t_1 t_2$ : function application
\end{bnf}
\end{center}

Function application is left-associative (so for all abstractions $f$, $f a b = (f a) b$), and
$\lambda$-abstractions extend as far as possible (e.g. $\lambda f. f a b = \lambda \, f. (f a b)$).

The $\lambda$-calculus includes three reductions. $\alpha$-conversion is the renaming of variables
such that the semantics of the program are not changed; terms which are semantically identical but
use different variable names are called $\alpha$-equivalent, which forms an equivalence relation.
$\beta$-reduction describes the idea of function application. The evaluation rules for the
$\lambda$-calculus are as follows \citep{wadler_programming_2022}.

\begin{align}
\label{equation:untyped_beta_rules}
\begin{split}
\inferrule{ }{(\lambda \, x. N)M \mapsto_{\beta} N[M/x]} \; (\beta) \quad
\inferrule{L \mapsto_{\beta} L'}{LM \mapsto_{\beta} L'M} \; (\xi_1) \quad\\
\inferrule{M \mapsto_{\beta} M'}{LM \mapsto_{\beta} LM'} \; (\xi_2) \quad
\inferrule{N \mapsto_{\beta} N'}{(\lambda \, x. N) \mapsto_{\beta} (\lambda \, x. N')} \; (\zeta)
\end{split}
\end{align}

Finally, we have $\eta$-reduction; for all $\lambda$-abstractions $\lambda \, x. f x$, we have that
$\lambda \, x. f x \mapsto_{\eta} f$ (this is the idea of function extensionality).

If further $\beta$-reducations do not simplify a term, we say that it is in its \textit{normal
form}. We shall represent an arbitrary number of successive $\beta$-reductions using the Kleene star
$\mapsto_{\beta^{\star}}$. The Church-Rosser theorem states that for any term $L$, if it
$\beta$-reduces to two terms $M$ and $N$, then there exists a common term $L'$ which both $M$ and
$N$ eventually $\beta$-reduce to \citep{church_properties_1936}.

Notably, some terms may not have a normal form. A well-known example is \textit{little omega} $\omega
\triangleq \lambda \, x. (x x)$ and \textit{omega} (sometimes called the \textit{omega combinator})
$\Omega \triangleq \omega \omega)$. $\Omega$ when applied to itself doesn't reduce any further.

\begin{equation*}
  (\lambda \, x. (x x)) (\lambda \, x. (x x)) \quad
  \mapsto_{\beta} \quad (\lambda \, x. (x x)) (\lambda \, x. (x x))
\end{equation*}

The \textit{y-combinator} $\mathcal{Y} \triangleq (\lambda \, f. (\lambda \, x. f (x x )) (\lambda
\, x. f (xx)))$ allows for recursion. It will $\beta$-reduce to the argument applied to itself,
$\mathcal{Y} f \mapsto_{\beta^{\star}} f (\mathcal{Y} f)$.

We say that these terms \textit{do not have a normal form}.

\subsection{The simply-typed lambda-calculus}
The simply-typed $\lambda$-calculus (STLC for short and sometimes given the symbol
$\lambda^{\rightarrow}$) is an extension of the untyped $\lambda$-calculus described above that was
developed by \citet{church_formulation_1940} which requires each term to have a \textit{type}. Terms
which do not have a normal form cannot be given a type, thus, all expressions will eventually reduce
to an irreducible expression---their normal form. This is also called \textit{strong normalisation}
\citep{pierce_types_2002}. However, this means we can longer represent all of the terms of the
untyped $\lambda$-calculus, thus, the STLC is not Turing-complete.

While Church originally used $\iota$ and $\sigma$ for base types, we will use $\nat$, for reasons
given in section \ref{appendix:typing_stlc}. Without base types, our computational model becomes
\textit{degenerate} (that is, there are no terms) \citep{pierce_types_2002}. As well as the base
type, we also have a function (or arrow) type. For some type $\tau$, writing $\tau \to \tau$ means
that this term can be applied using a term of type $\tau$ and result in a type $\tau$.

We will also need a \textit{type context} (also called \textit{type environment}), which will
usually be given the symbol $\Gamma$ or $\Delta$ and is separated using $\vdash$. This is a map from
variables to types $\Gamma \colon V \to T$ (`map' in the computing sense, it is not a complete map
as one might call a homomorphism). Types are written next to terms using a colon. If our context
contained the mapping $x \colon \nat$, then we could write a function which applies its argument to
$x$ like so,
\begin{equation*}
  x \colon \nat \in \Gamma \vdash (\lambda \, f \colon \nat \to \nat . f x) \colon \nat.
\end{equation*}

Sometimes we may choose to omit the type of the bound variable for clarity, so we could write
$(\lambda \, f. \lambda \, x. fx) \colon (\nat \to \nat) \to \nat$.

In the STLC, we can't give a type to little omega, since we can't give a type to both the argument
and the argument applied to itself ($(\lambda \, x  \colon ? . x x) \colon ??$). The typing rules for
STLC are given in section \ref{appendix:type_judgements}.

\subsection{System F.}
System F has been the formal background to what many modern programming
languages call \textit{generics}. For an anachronistic example, in Rust, we could write a function
which applies a function twice to an argument.

\begin{minted}[samepage]{rust}
fn twice<A, F>(f: F, x: A) -> A
where
    F: Fn(A) -> A,
{
    f(f(x))
}
\end{minted}

Since we used a \textit{type parameter} in the function's type signature, in this case called
\texttt{T}, we can use any appropriate function which has the type signature $\texttt{T} \to
\texttt{T}$. One such function is \texttt{u64::isqrt}, the (flooring) square root function. If this
function was invoked with \texttt{twice(u64::isqrt, 81)}, its output would be \texttt{3}. In this
case, the compiler is clever enough to infer that the type for \texttt{A} should be \texttt{u64}, so
we don't need to specify it manually.

System F is the STLC equipped with \textit{polymorphic types}, another term for type parameters. It
was independently discovered by Jean-Yves \citet{girard_interpretation_1972} and John
\citet{goos_towards_1974}. We can write this \textit{twice} function like so in System F:

\begin{equation*}
  (\Lambda \, T. \lambda \, f \colon T \to T . \lambda \, x \colon T . f (f x))
  \colon \forall T . (T \to T) \to T \to T.
\end{equation*}

If we wanted to use this function and be explicit about what type we're using, we could instantiate
it using [square brackets]. For instance,

\begin{align*}
  s \colon \nat \to \nat, z \colon \nat \in \Gamma \vdash
  &(\Lambda \, T. \lambda \, f \colon T \to T . \lambda \, x \colon T . f (f x))[\nat] s z \colon \nat\\
  &\mapsto_{\beta} (\lambda \, f \colon \nat \to \nat . \lambda \, x \colon \nat . f (f x)) s z \colon \nat\\
  &\mapsto_{\beta^{\star}} s s z \colon \nat.
\end{align*}

\section{Locally Nameless Representation}

\subsection{De Bruijn indices}
\label{section:background_debruijn}
Consider this expression,
\begin{equation*}
  x \colon \nat \in \Gamma \vdash (\lambda \, y \colon \nat \to \nat. y x) \colon \nat.
\end{equation*}

Suppose we move this expression into a context where we already have a bound
$y$.
\begin{equation*}
  x \colon \nat, y \colon \nat \to \nat \in \Gamma \vdash (\lambda \, y \colon \nat \to \nat. y x) \colon \nat.
\end{equation*}

It's unclear whether we are referring to the local $y$ or the $y$ in the cotntext. We can use an
$\alpha$-conversion and resolve this issue, applying $y \mapsto_{\alpha} f$ to the inner expression,
\begin{equation*}
  x \colon \nat, y \colon \nat \to \nat \in \Gamma \vdash \lambda \, f. f x \colon \nat,
\end{equation*}
which solves the problem. We can add further assumptions to our context without affecting the
semantics of the expression (for example, adding $k \colon \nat$ to $\Gamma$ doesn't cause any
problems). This is called weakening-invariance (taken from proof theory, where extra assumptions
make a theorem weaker).

Since we have these $\alpha$-equivalent expressions, we can say that we have \textit{quotient}
inductive definitions \citep{aydemir_engineering_2008}, so we have both an inductive definition of
the $\lambda$-calculus, but also (infinitely) many $\alpha$-equivalence classes which we need to
deal with. In some proof assistants, this makes proofs difficult \citep{pitts_locally_2023}.

We can solve this by using \textit{De Bruijn indices} which ensure that no matter what variables we
have in our context, we don't have any local variable names which could cause issues. In fact, we
can't perform $\alpha$-conversions anymore. In our example,
\begin{equation*}
  x \colon \nat, y \colon \nat \to \nat \in \Gamma \vdash (\lambda \, 0 2) \colon \nat.
\end{equation*}

However, if we were to change the context, we would need to change the index too. For example, if we
remove the $y$, then we need to reindex the $2$ to a $1$:
\begin{equation*}
  x \colon \nat, \in \Gamma \vdash (\lambda \, 0 1) \colon \nat,
\end{equation*}
We have lost weakening invariance \citep{aydemir_engineering_2008}.

\subsection{Locally Nameless Representation}
Using \textit{locally nameless representation}, we can get both purely inductive definitions
\textit{and} weakening-invariance. Free variables will use variable names while bound variables will
use indices. Our example becomes
\begin{equation*}
  x \colon \nat, \in \Gamma \vdash (\lambda \, 0 x) \colon \nat,
\end{equation*}
or with another variable in the context,
\begin{equation*}
  x \colon \nat, y \colon \nat \to \nat \in \Gamma \vdash (\lambda \, 0 x) \colon \nat.
\end{equation*}

As part of using locally nameless terms, common operations and properties (called `infrastructure'
by \citet{aydemir_engineering_2008}) need to be defined for the target language. A recent article by
Andrew \citet{pitts_locally_2023} uses Agda to explore an abstraction of this representation called
locally nameless sets, and shows that this infrastructure can be defined in a syntax-agnostic way.

The two fundamental operations on locally nameless terms is term opening and term closing. Term
opening will replace all occurences of a bound variable with a free variable, written $[i \to x] M$,
for example,
\begin{equation*}
  [0 \to y] (\lambda \, 0 q (\lambda \, 1 t 0)) \mapsto (\lambda \, y q (\lambda \, y t 0)).
\end{equation*}
Every occurence of the bound variable $0$ is replaced with the free variable $y$. Note how after we
go under a new $\lambda$-abstraction, we have to increment this index to $1$ to keep referring to
the same bound variable.

Closing works similarly, and is the inverse of opening:
\begin{equation*}
  [0 \rightarrow y] (\lambda \, y q (\lambda \, y t 0)) \mapsto (\lambda \, 0 q (\lambda \, 1 t 0)).
\end{equation*}

A term is said to be \textit{locally closed} up to level $i$ if it remains unchanged after opening
it at index $i$ with a string. We write (for some $i \in \nat$ and term $M$),
\begin{equation*}
  i \succ M \triangleq \forall j \geq i, \; \cof a , \; [j \to a] M = M.  
\end{equation*}
If it is locally closed at level $0$, we simply call it \textit{locally closed}. See
\ref{appendix:local_closure_proofs} for the Agda development.

More detail can be read in \citet{chargueraud_locally_2012} or section
\ref{appendix:opening_and_closing}.

\section{Evaluation strategy}
\label{section:evaluation_strategy}
There are several ways of evaluating the $\lambda$-calculus. The main question is whether to treat
$\lambda$-abstractions as values, or to reduce these if they are a redex.

The idea of reducible expressions, called a \textit{redex}, was introduced by Church
\citet[p.~56]{pierce_types_2002}. We refer to any expression of the form $(\lambda \, x. M) N$ as a
redex, since we can perform a $\beta$-reduction.

When evaluating, we need to consider some terms to be \textit{values}. These cannot be reduced any
further. One method is to consider $\lambda$-abstractions to be values and to only evaluated
\textit{closed} terms, that is, terms without any free variables. This is called weak-head
reduction, and the values are called weak-head normal forms \citep{wadler_programming_2022}. This
method is also used by popular programming languages such as Haskell \citep{hutchison_sharing_2005}.
The definition of $\lambda$-calculus as Church first described it uses what is nowadays referred to
as full normalisation \citep{wadler_programming_2022}. The reduction rule which is missing in
weak-head reduction is the $\zeta$ rule (see equation \ref{equation:untyped_beta_rules} on page
\pageref{equation:untyped_beta_rules}), or \textit{reducing under a $\lambda$-abstraction}.

One of the early explorations of weak-head reduction was made by \citet{cagman_combinatory_1998},
comparing it to combinatory logic. They presented the necessity of another reduction rule. Since
evaluation stops at $\lambda$-abstractions, the Church-Rosser property no longer applies (and, in
fact, the system is no longer Turing complete). While one could introduce specific rules when one
can reduce under a $\lambda$-abstraction to restore this property \citep{hutchison_sharing_2005},
another, simpler, method is to introduce primitives \citep{wadler_programming_2022}. These
primitives are a small subset of Scott and Plotkin's Programming Computable Functions (PCF)
\citep{plotkin_lcf_1977}, described in section \ref{section:stlc_terms}.

\section{Prior research}
System F was previously formalised in Agda by \citet{hutton_system_2019}. However, the authors of
that paper formalised a variant of System F with language extensions known as \textit{System
F$_{\omega \mu}$}. They also used a different approach, opting to make use of De Bruijn indices.
This paper will use the locally nameless representation, which hasn't been used for System F in Agda
before.

I have previously submitted some work on STLC using locally nameless representation for a course
called \textit{Types and Semantics of Programming Languages}. I have presented my prior work in
appendix \ref{appendix:tspl}. There are some new additions to this work which are presented in the
next chapter. To use the prior work, we need to import the appropriate modules.

\begin{code}
open import plfa_adaptions
open import tspl_prior_work
open import cofinite
\end{code}

\chapter{Substitution and Evaluation in STLC}
The remaining properties of STLC, including creating an evaluator, were missing from my submission
to TSPL. Since it is a necessary prelude to System F, this new work is presented here. As explained
in section \ref{section:evaluation_strategy}, one evaluation strategy is weak-head reduction. We
follow the methods presented in \citet[chapter~Properties]{wadler_programming_2022} and
\citet[section~5]{chargueraud_locally_2012}, as they have also used weak-head reduction. Thus,
evaluation will be restricted to closed terms only (those without free variables).

\section{Substitution}
We need to show that substituting preserves types. As mentioned, we restrict ourselves to only
substituting closed terms.
\begin{code}
{-# TERMINATING #-}
subst : ∀ {Γ x t u A B}
  → ∅ ⊢ u ⦂ A
  → Γ , x ⦂ A ⊢ t ⦂ B
    --------------------
  → Γ ⊢ [ x := u ] t ⦂ B
subst {x = y} ⊢u (⊢free {x = x} (H refl)) with y ≟lchar y
... | yes _   = weaken ⊢u
... | no  y≢y = contradiction refl y≢y
subst {x = y} ⊢u (⊢free {x = x} (T x≢y ∋x)) with y ≟lchar x
... | yes y≡x = contradiction (sym y≡x) x≢y
... | no  _   = ⊢free ∋x
subst {x = x} {t = ƛ t} ⊢u (⊢ƛ И⟨ Иe₁ , Иe₂ ⟩) =
  ⊢ƛ И⟨ x ∷ Иe₁
      , (λ a {a∉} →
        let a≢y   = ∉∷[]⇒≢ (proj₁ (∉-++ a∉))
            a∉Иe₁ = proj₂ (∉-++ a∉)
        in subst-open-context
          {t = t}
          (sym-≢ a≢y)
          (⊢⇒lc ⊢u)
          (subst ⊢u (swap a≢y (Иe₂ a {a∉Иe₁}))) )
      ⟩
subst ⊢u (⊢· ⊢t₁ ⊢t₂) = ⊢· (subst ⊢u ⊢t₁) (subst ⊢u ⊢t₂)
subst ⊢u ⊢zero = ⊢zero
subst ⊢u (⊢suc ⊢t) = ⊢suc (subst ⊢u ⊢t)
\end{code}

The property is proven by induction on the type judgement of the term \texttt{M}. Agda cannot
determine the termination of this function, and the problematic call is when the type judgement is a
$\lambda$-abstraction \texttt{ƛ M}. Specifically, it highlights the problematic code to be
\texttt{subst ⊢u (swap a≢y (Иe₂ a {a∉Иe₁}))}. Thus, I will only detail that step (technically, Agda
also complains about a problematic call for the application case, but this is caused by the
problematic $\lambda$-abstraction case).

Since we are inducting on the type judgement, the inductive hypothesis for a term \texttt{ƛ M} of
type \texttt{A ⇒ A'} states that the property $P$ holds for $P(\texttt{И⟨ Иe₁ , Иe₂ ⟩})$. Let
\texttt{b} be an appropriate \texttt{List Char} to supply to \texttt{Иe₂}, then it will return a
proof that \texttt{Γ , x ⦂ A , b ⦂ A' ⊢ [ 0 —→ b ] t ⦂ B}. In this case, the \texttt{subst} function
is called on \texttt{Иe₂} (with a \texttt{swap} function applied, but since this function doesn't
call \texttt{subst} and only operates on the context, this call is irrelevant to this termination
issue). Since we are deconstructing the type judgement and are calling \texttt{subst} on the term
\texttt{Иe₂} which makes up the input type judgement, this function call corresponds to the
inductive hypothesis, and is thus valid.

Substituting a term for an index is similar to the definition of the other substitution. This is,
confusingly, also called `opening' by \citet{chargueraud_locally_2012}.
\begin{code}
[_:→_]_ : ℕ → Term → Term → Term
[ k :→ u ] (free x) = free x
[ k :→ u ] (bound i) with k ≟ℕ i
... | yes _ = u
... | no  _ = bound i
[ k :→ u ] (ƛ t) = ƛ [ (suc k) :→ u ] t
[ k :→ u ] (t₁ · t₂) = [ k :→ u ] t₁ · [ k :→ u ] t₂
[ k :→ u ] ‵zero = ‵zero
[ k :→ u ] (‵suc t) = ‵suc ([ k :→ u ] t)
\end{code}

Using an index $i$ to open with $x \in \texttt{List Char}$ is the same as using the index
substitution with the term \texttt{free $x$}.
\begin{code}
—→≡:→free : ∀ {i : ℕ} {x : List Char} (t : Term)
  → [ i —→ x ] t ≡ [ i :→ free x ] t
—→≡:→free {i} {x} (free y) = refl
—→≡:→free {i} {x} (bound k) with i ≟ℕ k
... | yes _ = refl
... | no  _ = refl
—→≡:→free {i} {x} (ƛ t) = cong ƛ_ (—→≡:→free t)
—→≡:→free {i} {x} (t₁ · t₂) =
  cong₂ _·_ (—→≡:→free t₁) (—→≡:→free t₂)
—→≡:→free {i} {x} ‵zero = refl
—→≡:→free {i} {x} (‵suc t) = cong ‵suc_ (—→≡:→free t)
\end{code}

There are quite a few more properties of index substitution which \citet{chargueraud_locally_2012}
proves, but the only relevant one for evaluation is \texttt{subst-intro}. It proves that
substituting a term for an index is the same as first opening the term with an $x \in \texttt{List
Char}$ and then using the free variable substitution using this $x$.
\begin{code}
subst-intro : ∀ {x : List Char} {i : ℕ} (t u : Term)
  → x # t
  → [ i :→ u ] t ≡ [ x := u ] ([ i —→ x ] t)
subst-intro {x} (free y) u x#t with x ≟lchar y
... | yes refl with () ← x#t
... | no  x≢y  = refl
subst-intro {x} {i} (bound j) u x#t with i ≟ℕ j
... | no  i≢j  = refl
... | yes refl with x ≟lchar x
...   | yes refl = refl
...   | no  x≢x  = contradiction refl x≢x
subst-intro (ƛ t) u x#ƛt = cong ƛ_ (subst-intro t u (#-ƛ t x#ƛt))
subst-intro {x} (t₁ · t₂) u x#t =
  let ⟨ x#t₁ , x#t₂ ⟩ = #-· t₁ t₂ x#t in
    cong₂ _·_ (subst-intro t₁ u x#t₁) (subst-intro t₂ u x#t₂)
subst-intro ‵zero u x#t = refl
subst-intro (‵suc t) u x#st =
  cong ‵suc_ (subst-intro t u (#-‵suc t x#st))
\end{code}

Since we need to replace bound variables for free ones to perform a $\beta$-reduction, we should
prove that this substitution preserves types.
\begin{code}
subst-op : ∀ {Γ t u A B}
  → ∅ ⊢ u ⦂ A
  → Γ ⊢ ƛ t ⦂ A ⇒ B
    --------------------
  → Γ ⊢ [ 0 :→ u ] t ⦂ B
subst-op {t = t} {u = u} ⊢u (⊢ƛ И⟨ Иe₁ , Иe₂ ⟩) =
  let x                  = fresh (fv t ++ Иe₁)
      ⟨ x∉fv-t , x∉Иe₁ ⟩ = ∉-++ {xs = fv t} {ys = Иe₁}
                              (fresh-correct (fv t ++ Иe₁))
  in ≡-with-⊢ (subst ⊢u (Иe₂ x {x∉Иe₁}))
    (sym (subst-intro t u (∉fv⇒# x t (x∉fv-t))))
\end{code}

\section{Evaluation}
Using weak-head reduction, only $\lambda$-abstractions are values, together with the two primitives
that were introduced.
\begin{code}
data Value : Term → Set where
  V-ƛ : ∀ {t} → Value (ƛ t)
  V-zero : Value ‵zero
  V-suc : ∀ {t} → Value t → Value (‵suc t)
\end{code}

\citet{chargueraud_locally_2012} adds another requirement for $\lambda$-abstractions: $1 \succ M$,
or in other words, that $\lambda M$ is locally closed. However since we are only evaluating
well-typed terms, and all well-typed terms are locally closed (see section
\ref{appendix:type_judgements}). So this requirement isn't necessary here.

\citet{chargueraud_locally_2012} gives rules for reduction using locally closed terms. These are
encoded in Agda below.
\begin{code}
data _—→_ : Term → Term → Set where
  ξ₁ : ∀ {t₁ t₁' t₂}
    → t₁ —→ t₁'
    → LocallyClosed t₂
      -------------------
    → t₁ · t₂ —→ t₁' · t₂

  ξ₂ : ∀ {t₁ t₂ t₂'}
    → t₂ —→ t₂'
      ---------
    → t₁ · t₂ —→ t₁ · t₂'

  ξ-suc : ∀ {t t'}
    → t —→ t'
      ------------------
    → ‵suc t —→ ‵suc t'

  β : ∀ {t u}
    → 1 ≻ t
    → Value u
      -------
    → (ƛ t) · u —→ [ 0 :→ u ] t
\end{code}
Once again, the requirements for local closure could be removed, but I decided to keep them to
follow the rules presented in \citet{chargueraud_locally_2012}.

Following \citet{wadler_programming_2022}, we define some convenience functions, namely, reflexive
and transitive closure properties which will help reason about taking a reduction step. These follow
similar syntax to how equality reasoning is written in the Agda standard library
\citep{the_agda_community_agda_2024}.
\begin{code}
infix  2 _—↠_
infix  1 begin'_
infixr 2 _—→⟨_⟩_
infix  3 _∎'

data _—↠_ : Term → Term → Set where
  _∎' : ∀ M
      ---------
    → M —↠ M

  step—→ : ∀ L {M N}
    → M —↠ N
    → L —→ M
      ---------
    → L —↠ N

pattern _—→⟨_⟩_ L L—→M M—↠N = step—→ L M—↠N L—→M

begin'_ : ∀ {M N}
  → M —↠ N
    ------
  → M —↠ N
begin' M—↠N = M—↠N
\end{code}

There are two important properties which are required to implement evaluation. Progress, that terms
can always take a step, or are a value and are thus finished reducing, is presented below.
\begin{code}
data Progress (t : Term) : Set where
  step : ∀ {t'}
    → t —→ t'
      ----------
    → Progress t

  done :
      Value t
      ----------
    → Progress t

progress : ∀ {t A}
  → ∅ ⊢ t ⦂ A
    ----------
  → Progress t
progress (⊢ƛ x) = done V-ƛ
progress (⊢· ⊢t₁ ⊢t₂) with progress ⊢t₁
... | step t₁→t₁' = step (ξ₁ t₁→t₁' (⊢⇒lc ⊢t₂))
... | done V-ƛ with progress ⊢t₂
...   | step t₂→t₂' = step (ξ₂ t₂→t₂')
...   | done val    = step (β (i≻ƛt⇒si≻t (⊢⇒lc ⊢t₁)) val)
progress ⊢zero = done V-zero
progress (⊢suc ⊢t) with progress ⊢t
... | step t→t' = step (ξ-suc t→t')
... | done val  = done (V-suc val)
\end{code}

And preservation, that types are preserved when reducing.
\begin{code}
preserve : ∀ {t t' A}
  → ∅ ⊢ t ⦂ A
  → t —→ t'
    ----------
  → ∅ ⊢ t' ⦂ A
preserve (⊢· ⊢t₁ ⊢t₂) (ξ₁ t→t' _) = ⊢· (preserve ⊢t₁ t→t') ⊢t₂
preserve (⊢· ⊢t₁ ⊢t₂) (ξ₂ t→t') = ⊢· ⊢t₁  (preserve ⊢t₂ t→t')
preserve (⊢· ⊢t₁ ⊢t₂) (β x x₁) = subst-op ⊢t₂ ⊢t₁
preserve (⊢suc ⊢t) (ξ-suc t→t') = ⊢suc (preserve ⊢t t→t')
\end{code}

While STLC is not Turing complete \cite{church_formulation_1940}, we don't need to worry about the
halting problem. Still, we could try to evaluate a program that is very, very long. Rather than
reasoning about whether we can evaluate all programs, we can simply define a record which limits
evaluation to a certain number of reduction steps. Then we can use the preserve and progress
properties to make an \texttt{eval} function.
\begin{code}
record Gas : Set where
  eta-equality
  constructor gas
  field
    amount : ℕ

data Finished (t : Term) : Set where
  done : Value t → Finished t
  out-of-gas : Finished t

data Steps (t : Term) : Set where
  steps : ∀ {t'} → t —↠ t' → Finished t' → Steps t

eval : ∀ {t A} → Gas → ∅ ⊢ t ⦂ A → Steps t
eval {t} (gas zero) ⊢t = steps (t ∎') out-of-gas
eval {t} (gas (suc n)) ⊢t with progress ⊢t
... | done V-t = steps (t ∎') (done V-t)
... | step {t'} t→t' with eval (gas n) (preserve ⊢t t→t')
...   | steps t'→u fin-u = steps (t —→⟨ t→t' ⟩ t'→u) fin-u
\end{code}

We provide an example for evaluation. First, we require a a type derivation for $2+2$. We would show
that it evaluates to $4$, but because the evaluation proof requires more than eleven thousand lines
of code, it is omitted. But we encourage the reader to try it out for themselves. The proofs of
\texttt{⊢two} and \texttt{⊢plus} are long and are placed in section instead.

\begin{code}
two : Term
two = ƛ ƛ bound 1 · (bound 1 · bound 0)

plus : Term
plus = ƛ ƛ ƛ ƛ bound 3 · bound 1 · (bound 2 · bound 1 · bound 0)

suc' : Term
suc' = ƛ ‵suc (bound 0)

⊢two : ∅ ⊢ two ⦂ (‵ℕ ⇒ ‵ℕ) ⇒ ‵ℕ ⇒ ‵ℕ

⊢plus : ∀ {Γ A} → Γ ⊢ plus ⦂
  ((A ⇒ A) ⇒ A ⇒ A) ⇒ ((A ⇒ A) ⇒ A ⇒ A) ⇒ ((A ⇒ A) ⇒ A ⇒ A)

⊢suc' : ∀ {Γ} → Γ ⊢ suc' ⦂ ‵ℕ ⇒ ‵ℕ
⊢suc' = ⊢ƛ И⟨ [] , (λ _ → ⊢suc (⊢free H′)) ⟩

⊢2+2 : ∅ ⊢ plus · two · two · suc' · ‵zero ⦂ ‵ℕ
⊢2+2 = ⊢· (⊢· (⊢· (⊢· ⊢plus  ⊢two) ⊢two) ⊢suc') ⊢zero

-- Using Emacs, normalise "eval (gas 100) ⊢2+2" by pressing
-- C-c C-n.
\end{code}

\chapter{System F}
TODO.

\chapter{Conclusions}

\section{Final Reminder}

The body of your dissertation, before the references and any appendices,
\emph{must} finish by page~40. The introduction, after preliminary material,
should have started on page~1.

You may not change the dissertation format (e.g., reduce the font size, change
the margins, or reduce the line spacing from the default single spacing). Be
careful if you copy-paste packages into your document preamble from elsewhere.
Some \LaTeX{} packages, such as \texttt{fullpage} or \texttt{savetrees}, change
the margins of your document. Do not include them!

Over-length or incorrectly-formatted dissertations will not be accepted and you
would have to modify your dissertation and resubmit. You cannot assume we will
check your submission before the final deadline and if it requires resubmission
after the deadline to conform to the page and style requirements you will be
subject to the usual late penalties based on your final submission time.

\bibliographystyle{plainnat}
\bibliography{dissertation}


% You may delete everything from \appendix up to \end{document} if you don't need it.
\appendix

\chapter{Miscellaneous Proofs}
\label{appendix:misc_proofs}

Since some of these functions were already declared above, it would be an error to declare them
again. I decided to include the type signatures anyway for clarity.

\section{PLFA adaption}
\include{plfa_adaptions.lagda}

\chapter{Prior work submitted for TSPL}
\label{appendix:tspl}
\include{tspl_prior_work.lagda}

\chapter{STLC Evaluation}
\label{appendix:evaluation_proofs}
\begin{code}
-- ⊢two : ∅ ⊢ two ⦂ (‵ℕ ⇒ ‵ℕ) ⇒ ‵ℕ ⇒ ‵ℕ
⊢two = ⊢ƛ
  И⟨ []
  , (λ a → ⊢ƛ
    И⟨ (a ∷ [])
    , (λ b {b∉} →
      ⊢·
      (⊢free (T (sym-≢ (∉∷[]⇒≢ b∉)) H′))
      (⊢· (⊢free (T (sym-≢ (∉∷[]⇒≢ b∉)) H′)) (⊢free (H′)))) ⟩) ⟩

-- ⊢plus : ∀ {Γ A} → Γ ⊢ plus ⦂
-- ((A ⇒ A) ⇒ A ⇒ A) ⇒ ((A ⇒ A) ⇒ A ⇒ A) ⇒ ((A ⇒ A) ⇒ A ⇒ A)
⊢plus = ⊢ƛ
  И⟨ []
  , (λ a → ⊢ƛ
    И⟨ a ∷ []
    , (λ b {b∉} → ⊢ƛ
      И⟨ a ∷ b ∷ []
      , (λ c {c∉} → ⊢ƛ
        И⟨ a ∷ b ∷ c ∷ []
        , (λ d {d∉} →
        ⊢·
          (⊢·
            (⊢free (T (a≢d d∉) (T (a≢c c∉) (T (a≢b b∉) H′))))
            (⊢free (T (c≢d d∉) (H′))))
          (⊢·
            (⊢·
              (⊢free (T (b≢d d∉) (T (b≢c c∉) H′)))
              (⊢free (T (c≢d d∉) H′)))
            (⊢free H′))) ⟩) ⟩) ⟩) ⟩
  where
    a≢d : ∀ {a b c d} → d ∉ a ∷ b ∷ c ∷ [] → a ≢ d
    a≢d d∉ = sym-≢ (∉∷[]⇒≢ (proj₁ (∉-++ d∉)))
    a≢c : ∀ {a b c} → c ∉ a ∷ b ∷ [] → a ≢ c
    a≢c c∉ = sym-≢ (∉∷[]⇒≢ (proj₁ (∉-++ c∉)))
    a≢b : ∀ {a b} → b ∉ a ∷ [] → a ≢ b
    a≢b b∉ = sym-≢ (∉∷[]⇒≢ b∉)
    c≢d : ∀ {a b c d} → d ∉ a ∷ b ∷ c ∷ [] → c ≢ d
    c≢d {a} {b} d∉ =
      sym-≢ (∉∷[]⇒≢ (proj₂ (∉-++ {xs = a ∷ b ∷ []} d∉)))
    b≢d : ∀ {a b c d} → d ∉ a ∷ b ∷ c ∷ [] → b ≢ d
    b≢d {a} {b} d∉ =
      sym-≢ (∉∷[]⇒≢ (proj₂ (
        ∉-++
          {xs = a ∷ []}
          (proj₁ (∉-++ {xs = a ∷ b ∷ []} d∉)))))
    b≢c : ∀ {a b c} → c ∉ a ∷ b ∷ [] → b ≢ c
    b≢c {a} c∉ = sym-≢ (∉∷[]⇒≢ (proj₂ (∉-++ {xs = a ∷ []} c∉)))
\end{code}

\chapter{Compilation instructions}
\label{appendix:compilation_instructions}

This document is a literate Agda file. It has been tested to work with
\begin{itemize}
  \item Agda 2.7.0,
  \item the Agda Standard Library 2.1 \citep{the_agda_community_agda_2024},
  \item XeLaTeX 3.141592653-2.6-0.999996 (TeX Live 2024/Arch Linux 2024.2-4).
\end{itemize}

The full source code is available at [TO BE MADE PUBLIC LATER].

Since this document uses the Minted package [TODO: cite], XeLaTeX needs to be run with the
\texttt{--shell-escape} option. While Agda does provide its own typesetting of Agda code, it uses a
sans-serif typeface. I decided to use the Minted package to provide a monospace typeface for the
code blocks.

To typecheck the document, run Agda with the \texttt{--latex} option. If successful, it will give no
output and return an exit code \texttt{0}.

\end{document}
