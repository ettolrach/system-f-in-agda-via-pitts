\subsection{The lambda calculus.}
The $\lambda$-calculus (pronounced \textit{lambda calculus}), is a theoretical model of computation
developed by Alonzo Church in the 1930s \citep{church_set_1932} and is the basis for System F. It
looks and works similarly to familiar functional programming languages, yet its definition is as
minimal as possible while still being Turing-complete. Although Turing machines would be invented
after the $\lambda$-calculus \citep{turing_computable_1937}, `turing-complete' has become a
shorthand for `universal method of computation'. Such a universal method was not Church's initial
goal, but is why we're still interested in the $\lambda$-calculus.

The $\lambda$-calculus includes three reductions. $\alpha$-conversion is the renaming of variables
such that the semantics of the program are not changed; terms which are semantically identical but
use different variable names are called $\alpha$-equivalent, and as the name would imply, this is an
equivalence relation \citep{pierce_types_2002}.

$\beta$-reduction describes function application. The evaluation rules for the $\lambda$-calculus
are as follows \citep{wadler_programming_2022} (where $N[M/x]$ means replacing the term $M$ for any occurrence of $x$ in the term $N$).

\begin{equation}
\label{equation:untyped_beta_rules}
\begin{gathered}
  \inferrule{ }{(\lambda \, x. N)M \mapsto_{\beta} N[M/x]} \; (\beta) \quad
  \inferrule{L \mapsto_{\beta} L'}{LM \mapsto_{\beta} L'M} \; (\xi_1) \quad\\
  \inferrule{M \mapsto_{\beta} M'}{LM \mapsto_{\beta} LM'} \; (\xi_2) \quad
  \inferrule
    {N \mapsto_{\beta} N'}
    {(\lambda \, x. N) \mapsto_{\beta} (\lambda \, x. N')} \; (\zeta)
\end{gathered}
\end{equation}

The last reduction is $\eta$-reduction; for all $\lambda$-abstractions $\lambda \, x. L x$, we have
that $\lambda \, x. f x \mapsto_{\eta} f$.

If further $\beta$-reducations do not simplify a term, we say that it is in its \textit{normal
form}. We shall represent an arbitrary number of successive $\beta$-reductions using the Kleene star
$\mapsto_{\beta^{\star}}$. The Church-Rosser theorem states that for any term $L$, if it
$\beta$-reduces to two terms $M$ and $N$, then there exists a common term $L'$ which both $M$ and
$N$ eventually $\beta$-reduce to \citep{church_properties_1936}. This will be an important
consideration when choosing an evaluation strategy (see section \ref{background:evaluation_strategy}.)

Notably, some terms may not have a normal form. A well-known example is \textit{little omega}
$\omega \triangleq \lambda \, x. (x x)$ and \textit{omega} (sometimes called the \textit{omega
combinator}) $\Omega \, \triangleq \, \omega \omega$. When $\Omega$ is applied to itself, it doesn't
reduce any further.

\begin{equation*}
  (\lambda \, x. (x x)) (\lambda \, x. (x x)) \quad
  \mapsto_{\beta} \quad (\lambda \, x. (x x)) (\lambda \, x. (x x))
\end{equation*}

The \textit{y-combinator} $\mathcal{Y} \triangleq (\lambda \, f. (\lambda \, x. f (x x )) (\lambda
\, x. f (xx)))$ allows for recursion. It will $\beta$-reduce to the argument applied to itself,
$\mathcal{Y} L \mapsto_{\beta^{\star}} L (\mathcal{Y} L)$.

We say that these terms \textit{do not have a normal form}.

\subsection{The simply-typed lambda-calculus}
The simply-typed $\lambda$-calculus (STLC, sometimes given the symbol $\lambda^{\rightarrow}$) is an
extension of the untyped $\lambda$-calculus developed by Alonzo \citet{church_formulation_1940}. It
requires each term to have a \textit{type}. In the STLC, terms which do not have a normal form
cannot be given a type, thus, all expressions will eventually reduce to an irreducible
expression---their normal form. This is also called \textit{strong normalisation}
\citep{pierce_types_2002}. However, this means we can longer represent all of the terms of the
untyped $\lambda$-calculus (such as $\Omega$), thus, Turing-completeness is lost.

In the STLC, some base types need to be chosen. These are indeterminates which are not given
definitions. While Church originally used the symbols $\iota$ and $\sigma$ for base types, we will
use $\nat$, for reasons given in section \ref{background:evaluation_strategy}. Without base types,
our computational model becomes \textit{degenerate} (that is, there are no terms)
\citep{pierce_types_2002}. As well as the base type, we also have a function (or arrow) type. For
some types $\tau$ and $\sigma$, writing $\tau \to \sigma$ means that this term can be applied using
a term of type $\tau$ and result in a type $\sigma$.

We will also need a \textit{type context} (also called \textit{type environment}), which will
usually be given the symbol $\Gamma$ or $\Delta$ and is separated using $\vdash$. This is a partial
map from variables to types $\Gamma \colon V \to T$. Types are written next to terms using a colon.
For example, if the context contained the mapping $x \colon \nat$, then we could write a function
which applies $x$ to its argument;
\begin{equation*}
  x \colon \nat \in \Gamma \vdash (\lambda \, f \colon \nat \to \nat . f x) \colon \nat.
\end{equation*}

Sometimes we may choose to omit the type of the bound variable for clarity, so we could write
$(\lambda \, f. \lambda \, x. fx) \colon (\nat \to \nat) \to \nat$.

In the STLC, we can't give a type to little omega, since we can't give a type to both the argument
and the argument applied to itself ($(\lambda \, x  \colon ? . x x) \colon ??$). The typing rules for
STLC are given in section \ref{section:background_locally_nameless} (equation \ref{equation:stlc_type_judgements}).

\subsection{System F.}
System F has been the formal background to what many modern programming
languages call \textit{generics}. For an anachronistic example, in Rust, we could write a function
which applies a function twice to an argument.

\begin{minted}[samepage]{rust}
fn twice<T>(f: impl Fn(T) -> T, x: T) -> T
{
    f(f(x))
}
\end{minted}

Since we used a \textit{type parameter} in the function's type signature (here \texttt{T}), we can
use any appropriate function which has the type signature $\texttt{T} \to \texttt{T}$. One such
function is \texttt{u64::isqrt}, the (flooring) square root function. If this function was invoked
with \texttt{twice(u64::isqrt, 81)}, its output would be \texttt{3}. In this case, the compiler can
infer that the type for \texttt{T} should be \texttt{u64}, so we don't need to specify it
explicitly.

System F is the STLC equipped with \textit{polymorphic types}, another term for type parameters. It
was independently discovered by Jean-Yves \citet{girard_interpretation_1972} and John
\citet{goos_towards_1974}. We can write this \textit{twice} function like so in System F:

\begin{equation*}
  (\Lambda \, T. \lambda \, f \colon T \to T . \lambda \, x \colon T . f (f x))
  \colon \forall T . (T \to T) \to T \to T.
\end{equation*}

Unlike the Rust example, if we wanted to use this function, we would need to explicitly perform a
type application to specify what type we're using, as otherwise type inference is required. We write
type applications using [square brackets]. For instance,
\begin{align*}
  s \colon \nat \to \nat, z \colon \nat \in \Gamma \vdash
  &(\Lambda \, T. \lambda \, f \colon T \to T . \lambda \, x \colon T . f (f x))[\nat] s z \colon \nat\\
  &\mapsto_{\beta} (\lambda \, f \colon \nat \to \nat . \lambda \, x \colon \nat . f (f x)) s z \colon \nat\\
  &\mapsto_{\beta^{\star}} s s z \colon \nat.
\end{align*}

The type judgements for System F are given in section \ref{chapter4:type_judgements}.
