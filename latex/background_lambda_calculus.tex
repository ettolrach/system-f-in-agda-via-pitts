\subsection{The lambda calculus.}
The $\lambda$-calculus (pronounced \textit{lambda calculus}), is a theoretical model of computation
developed by Alonzo Church in the 1930s \citep{church_set_1932} and is the basis for System F. It
looks and works similarly to familiar functional programming languages, yet its definition is as
minimal as possible while still being Turing-complete. Although Turing machines would be invented
after the $\lambda$-calculus \citep{turing_computable_1937}, `turing-complete' has become a
shorthand for `universal method of computation'. Such a universal method was not Church's initial
goal, but is why we're still interested in the $\lambda$-calculus.

The $\lambda$-calculus includes three reductions. $\alpha$-conversion is the renaming of variables
such that the semantics of the program are not changed; terms which are semantically identical but
use different variable names are called $\alpha$-equivalent, which forms an equivalence relation
\citep{pierce_types_2002}.

$\beta$-reduction describes function application. The evaluation rules for the $\lambda$-calculus
are as follows \citep{wadler_programming_2022}.

\begin{align}
\label{equation:untyped_beta_rules}
\begin{split}
\inferrule{ }{(\lambda \, x. N)M \mapsto_{\beta} N[M/x]} \; (\beta) \quad
\inferrule{L \mapsto_{\beta} L'}{LM \mapsto_{\beta} L'M} \; (\xi_1) \quad\\
\inferrule{M \mapsto_{\beta} M'}{LM \mapsto_{\beta} LM'} \; (\xi_2) \quad
\inferrule{N \mapsto_{\beta} N'}{(\lambda \, x. N) \mapsto_{\beta} (\lambda \, x. N')} \; (\zeta)
\end{split}
\end{align}

Finally, we have $\eta$-reduction; for all $\lambda$-abstractions $\lambda \, x. L x$, we have that
$\lambda \, x. f x \mapsto_{\eta} f$.

If further $\beta$-reducations do not simplify a term, we say that it is in its \textit{normal
form}. We shall represent an arbitrary number of successive $\beta$-reductions using the Kleene star
$\mapsto_{\beta^{\star}}$. The Church-Rosser theorem states that for any term $L$, if it
$\beta$-reduces to two terms $M$ and $N$, then there exists a common term $L'$ which both $M$ and
$N$ eventually $\beta$-reduce to \citep{church_properties_1936}. This will be an important
consideration when choosing an evaluation strategy (see section \ref{section:evaluation_strategy}.)

Notably, some terms may not have a normal form. A well-known example is \textit{little omega} $\omega
\triangleq \lambda \, x. (x x)$ and \textit{omega} (sometimes called the \textit{omega combinator})
$\Omega \, \triangleq \, \omega \omega)$. $\Omega$ when applied to itself doesn't reduce any further.

\begin{equation*}
  (\lambda \, x. (x x)) (\lambda \, x. (x x)) \quad
  \mapsto_{\beta} \quad (\lambda \, x. (x x)) (\lambda \, x. (x x))
\end{equation*}

The \textit{y-combinator} $\mathcal{Y} \triangleq (\lambda \, f. (\lambda \, x. f (x x )) (\lambda
\, x. f (xx)))$ allows for recursion. It will $\beta$-reduce to the argument applied to itself,
$\mathcal{Y} f \mapsto_{\beta^{\star}} f (\mathcal{Y} f)$.

We say that these terms \textit{do not have a normal form}.

\subsection{The simply-typed lambda-calculus}
The simply-typed $\lambda$-calculus (STLC for short and sometimes given the symbol
$\lambda^{\rightarrow}$) is an extension of the untyped $\lambda$-calculus developed by Alonzo
\citet{church_formulation_1940}. It requires each term to have a \textit{type}. In the STLC, terms
which do not have a normal form cannot be given a type, thus, all expressions will eventually reduce
to an irreducible expression---their normal form. This is also called \textit{strong normalisation}
\citep{pierce_types_2002}. However, this means we can longer represent all of the terms of the
untyped $\lambda$-calculus (such as $\Omega$), thus, the STLC is not Turing-complete.

In the STLC, some base types need to be chosen. These are indeterminates which are not given
definitions. While Church originally used the symbols $\iota$ and $\sigma$ for base types, we will
use $\nat$, for reasons given in section \ref{section:evaluation_strategy}. Without base types, our
computational model becomes \textit{degenerate} (that is, there are no terms)
\citep{pierce_types_2002}. As well as the base type, we also have a function (or arrow) type. For
some types $\tau$ and $\sigma$, writing $\tau \to \sigma$ means that this term can be applied using
a term of type $\tau$ and result in a type $\sigma$.

We will also need a \textit{type context} (also called \textit{type environment}), which will
usually be given the symbol $\Gamma$ or $\Delta$ and is separated using $\vdash$. This is a partial
map from variables to types $\Gamma \colon V \to T$. Types are written next to terms using a colon.
If our context contained the mapping $x \colon \nat$, then we could write a function which applies
its argument to $x$ like so,
\begin{equation*}
  x \colon \nat \in \Gamma \vdash (\lambda \, f \colon \nat \to \nat . f x) \colon \nat.
\end{equation*}

Sometimes we may choose to omit the type of the bound variable for clarity, so we could write
$(\lambda \, f. \lambda \, x. fx) \colon (\nat \to \nat) \to \nat$.

In the STLC, we can't give a type to little omega, since we can't give a type to both the argument
and the argument applied to itself ($(\lambda \, x  \colon ? . x x) \colon ??$). The typing rules for
STLC are given in section \ref{appendix:type_judgements}.

\subsection{System F.}
System F has been the formal background to what many modern programming
languages call \textit{generics}. For an anachronistic example, in Rust, we could write a function
which applies a function twice to an argument.

\begin{minted}[samepage]{rust}
fn twice<T, F>(f: F, x: T) -> T
where
    F: Fn(T) -> T,
{
    f(f(x))
}
\end{minted}

Since we used a \textit{type parameter} in the function's type signature, in this case called
\texttt{T}, we can use any appropriate function which has the type signature $\texttt{T} \to
\texttt{T}$. One such function is \texttt{u64::isqrt}, the (flooring) square root function. If this
function was invoked with \texttt{twice(u64::isqrt, 81)}, its output would be \texttt{3}. In this
case, the compiler can infer that the type for \texttt{T} should be \texttt{u64}, so
we don't need to specify it manually.

System F is the STLC equipped with \textit{polymorphic types}, another term for type parameters. It
was independently discovered by Jean-Yves \citet{girard_interpretation_1972} and John
\citet{goos_towards_1974}. We can write this \textit{twice} function like so in System F:

\begin{equation*}
  (\Lambda \, T. \lambda \, f \colon T \to T . \lambda \, x \colon T . f (f x))
  \colon \forall T . (T \to T) \to T \to T.
\end{equation*}

Like in the Rust example, if we wanted to use this function, we would usually need to explicitly
perform a type application to specify what type we're using, though if it can be understood by the
reader from context, we will omit it. We write type applications using [square brackets]. For
instance,
\begin{align*}
  s \colon \nat \to \nat, z \colon \nat \in \Gamma \vdash
  &(\Lambda \, T. \lambda \, f \colon T \to T . \lambda \, x \colon T . f (f x))[\nat] s z \colon \nat\\
  &\mapsto_{\beta} (\lambda \, f \colon \nat \to \nat . \lambda \, x \colon \nat . f (f x)) s z \colon \nat\\
  &\mapsto_{\beta^{\star}} s s z \colon \nat.
\end{align*}
